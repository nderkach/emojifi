{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import emojifi as emojifi\n",
    "import glove as glove\n",
    "from utils import convert_to_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load words and embeddings from pretrained Twitter gloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = glove.read_glove_vecs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<user>', 0), ('.', 1), (':', 2), ('rt', 3), (',', 4), ('<repeat>', 5), ('<hashtag>', 6), ('<number>', 7), ('<url>', 8), ('!', 9)]\n",
      "---\n",
      "[(0, '<user>'), (1, '.'), (2, ':'), (3, 'rt'), (4, ','), (5, '<repeat>'), (6, '<hashtag>'), (7, '<number>'), (8, '<url>'), (9, '!')]\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check\n",
    "print(list(word_to_index.items())[:10])\n",
    "print(\"---\")\n",
    "print(list(index_to_word.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the gloVe embedding layer into Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68661  -1.0772    0.011114 -0.24075  -0.3422    0.64456   0.54957\n",
      "  0.30411  -0.54682   1.4695    0.43648  -0.34223  -2.7189    0.46021\n",
      "  0.016881  0.13953   0.020913  0.050963 -0.48108  -1.0764   -0.16807\n",
      " -0.014315 -0.55055   0.67823   0.24359  -1.3179   -0.036348 -0.228\n",
      "  1.0337   -0.53221  -0.52934   0.35537  -0.44911   0.79506   0.56947\n",
      "  0.071642 -0.27455  -0.056911 -0.42961  -0.64412  -1.3495    0.23258\n",
      "  0.25383  -0.10226   0.65824   0.16015   0.20959  -0.067516 -0.51952\n",
      " -0.34922 ]\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = emojifi.pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(embedding_layer.get_weights()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_count, X_train, Y_train, X_test, Y_test = emojifi.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print(max_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = emojifi.words_to_indices(X_train, word_to_index, max_word_count)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C=5)\n",
    "X_test_indices = emojifi.words_to_indices(X_test, word_to_index, max_word_count)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 10, 50)            60000050  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 60,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 60,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = emojifi.load_model((max_word_count,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Keras model\n",
    "\n",
    "NOTE: On 1070GTX this taxes ~8 seconds\n",
    "\n",
    "NOTE: Train accuracy is currently 96+%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.9428 - acc: 0.9621\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 704us/step - loss: 0.9452 - acc: 0.9621\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 740us/step - loss: 0.9638 - acc: 0.9394\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 744us/step - loss: 0.9499 - acc: 0.9545\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 746us/step - loss: 0.9431 - acc: 0.9621\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 751us/step - loss: 0.9594 - acc: 0.9470\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 741us/step - loss: 0.9539 - acc: 0.9470\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 745us/step - loss: 1.0241 - acc: 0.8864\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 753us/step - loss: 0.9719 - acc: 0.9318\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 758us/step - loss: 1.0274 - acc: 0.8788\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 736us/step - loss: 1.0186 - acc: 0.8864\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 719us/step - loss: 1.0503 - acc: 0.8485\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 880us/step - loss: 0.9951 - acc: 0.9091\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9541 - acc: 0.9545\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9610 - acc: 0.9470\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9624 - acc: 0.9394\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9598 - acc: 0.9470\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9655 - acc: 0.9394\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9516 - acc: 0.9545\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 814us/step - loss: 0.9534 - acc: 0.9470\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 845us/step - loss: 0.9504 - acc: 0.9545\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 697us/step - loss: 0.9805 - acc: 0.9242\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 764us/step - loss: 0.9584 - acc: 0.9470\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 805us/step - loss: 0.9579 - acc: 0.9470\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 743us/step - loss: 0.9579 - acc: 0.9470\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 877us/step - loss: 0.9580 - acc: 0.9470\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 702us/step - loss: 0.9577 - acc: 0.9470\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9503 - acc: 0.9545\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9473 - acc: 0.9545\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9726 - acc: 0.9318\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9504 - acc: 0.9545\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 850us/step - loss: 0.9504 - acc: 0.9545\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 736us/step - loss: 0.9525 - acc: 0.9545\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 758us/step - loss: 0.9428 - acc: 0.9621\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 816us/step - loss: 0.9456 - acc: 0.9621\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 811us/step - loss: 0.9427 - acc: 0.9621\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9545 - acc: 0.9470\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9504 - acc: 0.9545\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 926us/step - loss: 0.9592 - acc: 0.9470\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9504 - acc: 0.9545\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9504 - acc: 0.9545\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9572 - acc: 0.9470\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 741us/step - loss: 0.9504 - acc: 0.9545\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 832us/step - loss: 0.9506 - acc: 0.9545\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9503 - acc: 0.9545\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9561 - acc: 0.9470\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9503 - acc: 0.9545\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 823us/step - loss: 0.9504 - acc: 0.9545\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 754us/step - loss: 0.9543 - acc: 0.9470\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 777us/step - loss: 0.9503 - acc: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55c50773c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Test accuracy is falling between 75% and 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 5ms/step\n",
      "\n",
      "Test accuracy =  0.8035714200564793\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print(\"\\nTest accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
